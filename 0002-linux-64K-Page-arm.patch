 arch/arm/kernel/entry-common.S | 11 +++++++++++
 arch/arm/kernel/traps.c        |  4 ++++
 arch/arm/mm/Kconfig            | 10 ++++++++++
 arch/arm/mm/copypage-v6.c      |  4 ----
 arch/arm/mm/dump.c             |  5 ++++-
 arch/arm/mm/fault.c            | 20 +++++++++++++++++++-
 arch/arm/mm/mmu.c              | 32 ++++++++++++++++++++++++++++++--
 arch/arm/mm/pgd.c              |  2 ++
 arch/arm/mm/proc-macros.S      | 30 +++++++++++++++++++++++++++++-
 arch/arm/mm/proc-v6.S          | 24 +++++++++++++++++-------
 10 files changed, 126 insertions(+), 16 deletions(-)

diff --git a/arch/arm/kernel/entry-common.S b/arch/arm/kernel/entry-common.S
index ac86c3468..eae907061 100644
--- a/arch/arm/kernel/entry-common.S
+++ b/arch/arm/kernel/entry-common.S
@@ -403,8 +403,19 @@ ENDPROC(sys_fstatfs64_wrapper)
  * offset, we return EINVAL.
  */
 sys_mmap2:
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+#define PGOFF_SHIFT (PAGE_SHIFT - 12)
+#define PGOFF_MASK  ((1 << PGOFF_SHIFT) - 1)	
+	        tst     r5, #PGOFF_MASK
+	        moveq   r5, r5, lsr #PGOFF_SHIFT
+	        streq   r5, [sp, #4]
+	        beq     sys_mmap_pgoff
+	        mov     r0, #-EINVAL
+	        ret     lr
+#else	
 		str	r5, [sp, #4]
 		b	sys_mmap_pgoff
+#endif
 ENDPROC(sys_mmap2)
 
 #ifdef CONFIG_OABI_COMPAT
diff --git a/arch/arm/kernel/traps.c b/arch/arm/kernel/traps.c
index 195dff58b..8e332eaaa 100644
--- a/arch/arm/kernel/traps.c
+++ b/arch/arm/kernel/traps.c
@@ -816,7 +816,11 @@ void __init early_trap_init(void *vectors_base)
 
 	kuser_init(vectors_base);
 
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	flush_icache_range(vectors, vectors + PAGE_SIZE);
+#else
 	flush_icache_range(vectors, vectors + PAGE_SIZE * 2);
+#endif
 #else /* ifndef CONFIG_CPU_V7M */
 	/*
 	 * on V7-M there is no need to copy the vector table to a dedicated
diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig
index 58afba346..54b4a8058 100644
--- a/arch/arm/mm/Kconfig
+++ b/arch/arm/mm/Kconfig
@@ -973,6 +973,16 @@ config MIGHT_HAVE_CACHE_L2X0
 	  instead of this option, thus preventing the user from
 	  inadvertently configuring a broken kernel.
 
+config ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+        bool "64KB MMU page size support"
+        help
+          The kernel and page-table will use large 64KB pages.
+          Note that this feature enables support for large storage volumes
+          at the expense of higher memory fragmentation by enabling the
+          use of up to 64KB block sizes.
+          This is commonly required to access file systems used by
+          commercial NAS devices.
+
 config CACHE_L2X0
 	bool "Enable the L2x0 outer cache controller" if MIGHT_HAVE_CACHE_L2X0
 	default MIGHT_HAVE_CACHE_L2X0
diff --git a/arch/arm/mm/copypage-v6.c b/arch/arm/mm/copypage-v6.c
index d8a115de5..562fcb1ac 100644
--- a/arch/arm/mm/copypage-v6.c
+++ b/arch/arm/mm/copypage-v6.c
@@ -17,10 +17,6 @@
 
 #include "mm.h"
 
-#if SHMLBA > 16384
-#error FIX ME
-#endif
-
 static DEFINE_RAW_SPINLOCK(v6_lock);
 
 /*
diff --git a/arch/arm/mm/dump.c b/arch/arm/mm/dump.c
index fb688003d..ffe1ed764 100644
--- a/arch/arm/mm/dump.c
+++ b/arch/arm/mm/dump.c
@@ -309,8 +309,11 @@ static void walk_pte(struct pg_state *st, pmd_t *pmd, unsigned long start,
 	pte_t *pte = pte_offset_kernel(pmd, 0);
 	unsigned long addr;
 	unsigned i;
-
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	for (i = 0; i < PTRS_PER_PTE_REAL; i++, pte += PTE_STEP) {
+#else
 	for (i = 0; i < PTRS_PER_PTE; i++, pte++) {
+#endif
 		addr = start + i * PAGE_SIZE;
 		note_page(st, addr, 5, pte_val(*pte), domain);
 	}
diff --git a/arch/arm/mm/fault.c b/arch/arm/mm/fault.c
index bc8779d54..ab192f313 100644
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -26,6 +26,19 @@
 
 #ifdef CONFIG_MMU
 
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+static long long get_large_pte_hw_val(pte_t *pte)
+{
+    unsigned long pte_ptr = (unsigned long)pte;
+    unsigned long tmp = pte_ptr;
+
+    pte_ptr += (PTE_HWTABLE_PTRS * sizeof(void *));
+    pte_ptr &= ~0x7FC;
+    tmp &= 0x7FC & (~(((PAGE_SHIFT - 12) - 1) << 7));
+    pte_ptr += (tmp << (PAGE_SHIFT - 12));
+    return (long long)pte_val(*(pte_t *)pte_ptr);
+}
+#endif
 /*
  * This is useful to dump out the page tables associated with
  * 'addr' in mm 'mm'.
@@ -86,9 +99,14 @@ void show_pte(const char *lvl, struct mm_struct *mm, unsigned long addr)
 		pte = pte_offset_map(pmd, addr);
 		pr_cont(", *pte=%08llx", (long long)pte_val(*pte));
 #ifndef CONFIG_ARM_LPAE
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+		pr_cont(", *ppte=%08llx", get_large_pte_hw_val(pte));
+		
+#else
 		pr_cont(", *ppte=%08llx",
 		       (long long)pte_val(pte[PTE_HWTABLE_PTRS]));
-#endif
+#endif /* CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT */
+#endif /* CONFIG_ARM_LPAE */
 		pte_unmap(pte);
 	} while(0);
 
diff --git a/arch/arm/mm/mmu.c b/arch/arm/mm/mmu.c
index 274e4f73f..4ef8b58a3 100644
--- a/arch/arm/mm/mmu.c
+++ b/arch/arm/mm/mmu.c
@@ -346,7 +346,11 @@ static pte_t bm_pte[PTRS_PER_PTE + PTE_HWTABLE_PTRS]
 
 static pte_t * __init pte_offset_early_fixmap(pmd_t *dir, unsigned long addr)
 {
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	return &bm_pte[pte_index(addr) * PTE_STEP];
+#else
 	return &bm_pte[pte_index(addr)];
+#endif
 }
 
 static pte_t *pte_offset_late_fixmap(pmd_t *dir, unsigned long addr)
@@ -710,7 +714,9 @@ static pte_t * __init arm_pte_alloc(pmd_t *pmd, unsigned long addr,
 				void *(*alloc)(unsigned long sz))
 {
 	if (pmd_none(*pmd)) {
-		pte_t *pte = alloc(PTE_HWTABLE_OFF + PTE_HWTABLE_SIZE);
+	        pte_t *pte = alloc(round_up(PTE_HWTABLE_OFF +
+					    PTE_HWTABLE_SIZE,
+					    PAGE_SIZE));
 		__pmd_populate(pmd, __pa(pte), prot);
 	}
 	BUG_ON(pmd_bad(*pmd));
@@ -734,7 +740,11 @@ static void __init alloc_init_pte(pmd_t *pmd, unsigned long addr,
 		set_pte_ext(pte, pfn_pte(pfn, __pgprot(type->prot_pte)),
 			    ng ? PTE_EXT_NG : 0);
 		pfn++;
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	} while (pte += PTE_STEP, addr += PAGE_SIZE, addr != end);
+#else
 	} while (pte++, addr += PAGE_SIZE, addr != end);
+#endif
 }
 
 static void __init __map_init_section(pmd_t *pmd, unsigned long addr,
@@ -1343,7 +1353,16 @@ static void __init devicemaps_init(const struct machine_desc *mdesc)
 	/*
 	 * Allocate the vector page early.
 	 */
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+        /*
+	 * With large page support, the pages are at least 8K, so
+	 * there is enough space in one page for the stubs that are
+	 * copied at 4K offset.
+	 */
+	vectors = early_alloc(PAGE_SIZE);
+#else
 	vectors = early_alloc(PAGE_SIZE * 2);
+#endif
 
 	early_trap_init(vectors);
 
@@ -1413,13 +1432,22 @@ static void __init devicemaps_init(const struct machine_desc *mdesc)
 		map.type = MT_LOW_VECTORS;
 		create_mapping(&map);
 	}
-
+	
+	/*
+	 * With large page support, the pages are at least 8K, so this
+	 * hardware page was already mapped. Actually the hardcoded
+	 * 4KB offset cause trouble with the virtual address passed
+	 * to create_mapping: the address is no more aligned to a
+	 * page.
+	 */
+#ifndef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
 	/* Now create a kernel read-only mapping */
 	map.pfn += 1;
 	map.virtual = 0xffff0000 + PAGE_SIZE;
 	map.length = PAGE_SIZE;
 	map.type = MT_LOW_VECTORS;
 	create_mapping(&map);
+#endif
 
 	/*
 	 * Ask the machine support to map in the statically mapped devices.
diff --git a/arch/arm/mm/pgd.c b/arch/arm/mm/pgd.c
index f8e9bc58a..d51b1e244 100644
--- a/arch/arm/mm/pgd.c
+++ b/arch/arm/mm/pgd.c
@@ -119,7 +119,9 @@ pgd_t *pgd_alloc(struct mm_struct *mm)
 		init_pmd = pmd_offset(init_pud, 0);
 		init_pte = pte_offset_map(init_pmd, 0);
 		set_pte_ext(new_pte + 0, init_pte[0], 0);
+#ifndef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT		
 		set_pte_ext(new_pte + 1, init_pte[1], 0);
+#endif
 		pte_unmap(init_pte);
 		pte_unmap(new_pte);
 	}
diff --git a/arch/arm/mm/proc-macros.S b/arch/arm/mm/proc-macros.S
index fa6999e24..99acbcb02 100644
--- a/arch/arm/mm/proc-macros.S
+++ b/arch/arm/mm/proc-macros.S
@@ -154,8 +154,16 @@
 
 	bic	r3, r1, #0x000003fc
 	bic	r3, r3, #PTE_TYPE_MASK
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	bic     r3, r3, #0x00000F000
+#endif
 	orr	r3, r3, r2
-	orr	r3, r3, #PTE_EXT_AP0 | 2
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+	orr     r3, r3, #PTE_EXT_AP0 | PTE_TYPE_LARGE
+#else
+	orr     r3, r3, #PTE_EXT_AP0 | PTE_TYPE_SMALL
+#endif
+
 
 	adr	ip, \pfx\()_mt_table
 	and	r2, r1, #L_PTE_MT_MASK
@@ -183,8 +191,28 @@
 	tstne	r1, #L_PTE_NONE
 	movne	r3, #0
 
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT
+
+	/* Bits 6, 7, 8 SBZ */
+	bic     r3, r3, #0x000001c0
+
+	/*	
+         * Repeat the hw entry 16 times in case of 64k page
+         * This is a requirement from the hw ;
+         * linux ptes need not be repeated.
+        */
+	mov     r1, #16
+.Lrpt_for_hw:
+	str     r3, [r0]
+	mcr     p15, 0, r0, c7, c10, 1          @ flush_pte
+	add     r0, r0, #4
+	subs    r1, r1, #1
+	bne     .Lrpt_for_hw
+
+#else /* CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT */
 	str	r3, [r0]
 	mcr	p15, 0, r0, c7, c10, 1		@ flush_pte
+#endif /* CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT */
 	.endm
 
 
diff --git a/arch/arm/mm/proc-v6.S b/arch/arm/mm/proc-v6.S
index a0618f3e6..1b5318394 100644
--- a/arch/arm/mm/proc-v6.S
+++ b/arch/arm/mm/proc-v6.S
@@ -95,21 +95,31 @@ ENTRY(cpu_v6_dcache_clean_area)
  */
 ENTRY(cpu_v6_switch_mm)
 #ifdef CONFIG_MMU
-	mov	r2, #0
 	mmid	r1, r1				@ get mm->context.id
-	ALT_SMP(orr	r0, r0, #TTB_FLAGS_SMP)
-	ALT_UP(orr	r0, r0, #TTB_FLAGS_UP)
-	mcr	p15, 0, r2, c7, c5, 6		@ flush BTAC/BTB
-	mcr	p15, 0, r2, c7, c10, 4		@ drain write buffer
-	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
 #ifdef CONFIG_PID_IN_CONTEXTIDR
 	mrc	p15, 0, r2, c13, c0, 1		@ read current context ID
 	bic	r2, r2, #0xff			@ extract the PID
 	and	r1, r1, #0xff
 	orr	r1, r1, r2			@ insert into new context ID
 #endif
+	mov	r2, #0
+	ALT_SMP(orr	r0, r0, #TTB_FLAGS_SMP)
+	ALT_UP(orr	r0, r0, #TTB_FLAGS_UP)
+	mcr	p15, 0, r2, c7, c5, 6		@ flush BTAC/BTB
+#ifdef CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT	
+	mcr     p15, 0, r2, c7, c10, 4          @ dsb
+	mcr     p15, 0, r2, c13, c0, 1          @ set reserved context ID
+	mcr     p15, 0, r2, c7, c5, 4           @ isb
+	mcr     p15, 0, r0, c2, c0, 0           @ set TTB 0
+	mcr     p15, 0, r2, c7, c5, 4           @ isb
+	mcr     p15, 0, r1, c13, c0, 1          @ set context ID
+	mcr     p15, 0, r2, c7, c5, 4           @ isb
+#else	
+	mcr	p15, 0, r2, c7, c10, 4		@ drain write buffer
+	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
 	mcr	p15, 0, r1, c13, c0, 1		@ set context ID
-#endif
+#endif	/* CONFIG_ARM_64KB_MMU_PAGE_SIZE_SUPPORT */
+#endif	/* CONFIG_MMU */
 	ret	lr
 
 /*
